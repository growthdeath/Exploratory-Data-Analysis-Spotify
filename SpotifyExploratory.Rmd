---
title: 'Spotify Data : Exploratory Analysis with R'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Preliminaries
First, I downloaded and installed the packages required to perform some simple analysis and data visualisation. 

```{r loadlib, echo=T, results='hide', message=F, warning=F}
library(supernova)
library(readr)
library(tidyverse)
library(ggplot2)
library(lm.beta)
library(ggpubr)
library(mosaic)
library(Hmisc)
library(dplyr)
library(kableExtra)
```

# THE DATA
## About the Data
Spotify is a Swedish audio streaming and media services provider, founded in April 2006 by Daniel Ek and Martin Lerentzon. With an estimated 551 million million active users and 220 million paying subscribers (as of Q1 of 2023), Spotify is one the largest music streaming service providers. 

  Spotify offers its users digital copyright restricted recorded visual and audio content, from music and music videos, to podcasts and audio books. As a freemium service, basic features are free with advertisements, with premium features, such as offline and advertisement free listening, being offered via paid subscription. 
  
  While Spotify has experienced year-on-year increases in total revenue, with a total revenue of 11.72bn USD in 2022, it has never published a net profit. Of greater concern, Spotify experienced an overall loss of 331 million USD in Q1 of 2023, leading to share prices to fall by 14%. In an attempt to mitigate their financial struggles, the price of a premium subscriptions were increased across the US, UK and Australia in July 2023: even with record levels of active users, they are still pushed to increase prices at a time of high inflation and economic uncertainty. 
  
  Spotify owes its popularity to its ability to provide users with their preferred music, when they want it, how they want it, and in playlists that are designed for their preferences. By examining the qualities of the music that has historically been most popular, Spotify can make informed decisions regarding which new and upcoming artists to support, and know more about its audiences preferences. 
  
  In this R project, I will examine the top10s dataset, developed by data scientist Leonardo Henrique which  consists of 603 songs that were in the top songs of the year worldwide from 2010 to 2019 (as measured by Billboard). It contains the following variables:
  
  *...1*: ID
  *title*: Song title
  *artist*: name of the musician, band or artist
  *top genre* : Most salient genre of the song
  *year*: year the song was on the Billboard
  *bpm* : beats per minute (tempo of the song)
  *nrgy*: The energy of the song (higher values - faster, more energetic)
  *dnce*: The 'danceability' of the song (higher values indicate it is more suitable for dancing based on its tempo, rhythm stability, beat strength)
  *dB* : Decibel - loudness of the song
  *live*: Likelihood that the song was recorded with a live audience
  *val*: Valence (higher values indicate the song is more 'positive', happy or cheerful)
  *dur*: The duration of the song in seconds
  *acous*: Likelihood that the song is acoustic
  *spch*: Speechiness (higher values indicate more spoken words)
  *pop*: Popularity (higher values indicate higher popularity)
  
## Loading the Data

First, I have loaded the data into the R environment, and reviewing the head, or the first six rows, of the dataset. 
```{r}
spotify_data <- read_csv("Desktop/R Portfolio/Exploratory Data Analysis/top10s.csv")
```

# DATA INSPECTION AND CLEANING 

First, I inspected the data be calling the column names, the first 6  rows of the data frame and a list of columns and data types.

```{r}
colnames(spotify_data) 
head(spotify_data)
str(spotify_data)
```
As columns 6-15 have numeric data that indicates a variable related to the track characteristics, I am also going to call a statistical summary of the numeric data

```{r}
summary(spotify_data[c(6:15)])
```
Now that I have looked at the data, serveral issues have been identified : 
1. Column 1 does not have a name
2. Some songs seem to have the value '0', which may indicate a data entry error
3. There may be repeated songs in the dataset, which should be deleted. 

## Renaming the First Column 
The first column will be renamed 'ID_No', and I will check that this has been achieved by calling the column names again
```{r}
names(spotify_data)[1]<- "ID_No"
names(spotify_data)[4]<- "genre"
colnames(spotify_data)
```

## Deleting Repeated Songs 
First, I have listed the distinct values in the columns, and checking for any repeated values
```{r}
unique(spotify_data$title)
unique(spotify_data$year)
```
While it appears that the dataset does range from 2010-2019 as stated, the presence of 584 unique song names in a data set of 603 songs is cause for concern. 

I am going to call the duplicated values to examine them 
```{r}
spotify_data$title[duplicated(spotify_data$title)]
```
Upon further research, the majority of these songs have the same issue : they were published and entered the charts toward the end of one year, but persisted in the charts until the next year, meaning that they were entered into the data set twice. To resolve this, and remove the duplicate entries, I will place all songs within the year they were published.
- "Hello"," I Like It" and "Say Something" are only considered a "duplicate entry" in that two very popular songs on two separate years had the same title, so I will not remove these from the data set. 
- Sugar is duplicated and has been entered twice with different popularity scores. Upon further research, the song has a popularity score of 81, so the entry with the erroneous score will be deleted

```{r}
spotify_data <- 
  spotify_data%>% 
  filter(title != 'Just the Way You Are' | year != 2011) %>%
filter(title != 'Marry You' | year != 2011) %>%
filter(title != 'Written in the Stars (feat. Eric Turner)' | year != 2011) %>%
filter(title != 'Castle Walls (feat. Christina Aguilera)' | year != 2011) %>%
filter(title != 'We Are Never Ever Getting Back Together' | year != 2013) %>%
filter(title != 'A Little Party Never Killed Nobody (All We Got)' | year != 2014) %>%
filter(title != 'Sugar' | pop != 66) %>%
filter(title != 'The Hills' | year != 2016) %>%
filter(title != 'Love Yourself' | year != 2016) %>%
filter(title != 'Company' | year != 2016)  %>%
filter(title != "Runnin' (Lose It All)" | year != 2016) %>%
filter(title != 'Here' | year != 2016) %>%
filter(title != 'All I Ask' | year != 2017) %>%
filter(title != 'First Time' | year != 2018) %>%
filter(title != 'Kissing Strangers' | year != 2019)
```

## Checking songs with values of '0'
Having a song with a value of 0 is not, in it self, cause for concern because it is possible for a song to have very low energy, acousticity, popularity or danceability. However, if a song has multiple 0 values, this may indicate a data entry error, and thus that song should be deleted. 

```{r}
spotify_data %>% 
  select_all() %>% 
  filter(bpm == 0 |
         nrgy == 0 |
         dnce == 0 |
         dB == 0 |
         live == 0 |
         dur == 0 |
         spch == 0 |
         pop  == 0 )
```
Song number 443 appears to have an unusually large number of values of 0. As this is a large dataset, this song will be removed

```{r}
spotify_data <- spotify_data %>% 
  filter(ID_No != 443)
```

## Data Set Description After Cleaning 

After cleaning, this data set contains 588 that were in the top songs of the year from 2010 to 2019 (as measured by Billboard. 15 songs were removed due to data entry errors or duplicate entries. 

# ANALYSIS GOALS

The business objective of this analysis would be to *identify key factors that influence a track's popularity, finding potential trends in popular music that will provide a guideline for Spotify's decisions to support new and upcoming artists*
  Questions: 
  1.Which were the most popular songs? 
  2.Which were the most popular genres?
  3.Which were the most popular artists from 2010-2019?
  4.Have the characteristics of top songs (danceability,energy,valence,live) changed over time? 
  5.What is the relationship between energy and valence?
  
Using these insights, I also am going to train and build a classifier to predict a song's genre based on its characteristics : this could assist Spotify's data analysts in categorisation and clustering of song types. 


## Songs
Now, I want to answer the first question : Which is the most popular songs? 

```{r}
most_popular <- 
  spotify_data%>%
  arrange(desc(pop))%>%
  group_by(artist)
most_popular
```
The most popular song in the dataset, as of 2019, was Memories by Maroon 5. To ensure the popularity index is not skewed by duration since the song's publication (for example, older songs may be less popular in 2019 than in the year of their initial release), I am going to plot the most popular song of the year, for every year.

```{r}
most_popular_song <- spotify_data %>% 
  group_by(year) %>% 
  filter(pop == max(pop)) %>% 
  arrange(desc(year))
 
most_popular_song_tab <- most_popular_song %>% 
  select(title,
         artist,
         year, dur,
         pop)
most_popular_song_tab %>%
  kbl(caption = "Most Popular Songs of The Year 2010-2019") %>%
  kable_classic(html_font = "Alrai")
```
### Summary
From merely observing this table, there are serveral details to note about the most popular songs of the year throughout the decade: 
- Five of the songs are in the 'dance pop' genre, and four of the songs are in the 'pop' genre, indicating 'pop', as a genre, to be a high predictor of popularity and song success. 
- In both 2015 and 2016 there were ties between three songs for the title of most popular song. This may indicate that a particular phenomenon was occuring in the music industry at the time, or it may be a coincidence. 


## Artists

Song popularity is an important variable to observe, but more important, from the perspective of business managers deciding whether to sign a record deal, is the popularity and success of artists. By knowing the characteristics that predict artist success, both Spotify and the artists they support can make more informed decisions. 

I have visualised the artists that are most present frequently in the dataset, to find out which artists produced the largest amount of top songs from 2010 to 2019. 

```{r}
most_popular_artist <-
  most_popular%>%
  count(artist)%>%
  arrange(desc(n))

most_popular_artist%>%
  head(15)%>%
  ggplot(aes(x=reorder(artist,n),y=n))+
  geom_col(fill="green4")+ggtitle("15 Most Popular Artists")+
  ylab("Amount of Appearances On Billboard From 2010-2019")+
  xlab("Artists")+
  coord_flip()
```

### Summary 

This bar chart provides a wealth of valuable information : 
- 6 of the top artists are women, 7 are men, and 2 are bands. In light of this information, gender may be discarded as a predictor of success, but executives may be more inclined to support independent artists, as opposed to bands or groups. 

- The majority of the chart appears to consist of artists of US origin. Examining the processes of the US music industry to explore how and why this has occured may allow Spotify to support artists from other countries such that they can experience similar success. 

- Katy Perry is the most frequently appearing artist on the billboard, appearing a total of 15 times from 2010 to 2017. Investing in artists who are able to sustain success over multiple years should be a key goal for Spotify. 


## Genre
First, I want to see all the types of genres in the dataset, and their frequencies
```{r}
 genre_table <- table(spotify_data$genre)
View(genre_table)
```

```{r}
# re-order levels
compute <- function(x) {
  genre_table <- table(x)
  factor(x, levels = names(sort(genre_table)))
}
  
# plotting the data
ggplot(data=spotify_data, aes(x = compute(genre))) +
  geom_bar() +
  ylab('Frequency of Appearance')+
  xlab("Genre")+
   theme(axis.text.x=element_text(angle=45,hjust=1))
```

### Summary 
From merely observing this table and bar chart, there are serveral details to note about the most frequently occuring genres throughout the decade: 
- Dance Pop occurs 325 times in the dataset, meaning that over half of the songs that were in the top 10 billboard throughout the 2010s belonged to the dance pop genre

- Of the 50 genres in the dataset, 15 only appear once. Without further data, it is unknown whether these were genres with a loyal but niche following, or 'one hit wonders' who surged in popularity overnight, but were unable to sustain their success. While investment in artists in the former category would be wise, supporting all artists in niche genres may be risky and unsustainable. 

- Of the five most frequently occuring genres, four are derivatives of pop : Dance Pop, Electropop, Canadian pop and Barbadian pop. While supporting a 'pop' artist may appear like useful insight, without further details as to what constitutes 'pop' music, and what trends in music have been over the decade, this detail means little. 



## Trends Over Time

###Danceability
As Dance Pop was the most frequently occuring genre in the billboard, I wanted to find out if there has been any change in the mean danceability scores of popular songs over time. 
```{r}
# Finding the average danceability score of songs for each year
mean_dnce<- 
  spotify_data %>%
  group_by(year) %>%
  summarise_at(vars(dnce), list(dnce = mean))
mean_dnce
```
Now, any changes in the mean danceability score can be visualised here
```{r}
ggplot(mean_dnce, aes(x = year, y = dnce)) +
  geom_line() +
  labs(title = "Changes in Danceability of Popular Songs over Time",
       x = "Year",
       y = "Mean Danceability Score")
```

### Energy
Energy may be a significant component of the danceability score, and/or of the pop genre, so I also examined the trends in average song energy over time 
```{r}
mean_nrgy<- 
  spotify_data %>%
  group_by(year) %>%
  summarise_at(vars(nrgy), list(nrgy = mean))
mean_nrgy
```
Now, any changes in the mean energy score can be visualised here
```{r}
ggplot(mean_nrgy, aes(x = year, y = nrgy)) +
  geom_line() +
  labs(title = "Changes in Energy of Popular Songs over Time",
       x = "Year",
       y = "Mean Energy Score")
```
Both average energy and average danceability of popular songs appears to have decreased : audience tastes have changed throughout the decade!

###Valence
As both the average Energy and Danceability of popular songs has decreased over time, I wanted to examine whether the mean valence, or 'Positivity' of songs has also decreased throughout the decade. 
```{r}
mean_val<- 
  spotify_data %>%
  group_by(year) %>%
  summarise_at(vars(val), list(valence = mean))
mean_val
```
Now, any changes in the mean energy score can be visualised here
```{r}
ggplot(mean_val, aes(x = year, y = valence)) +
  geom_line() +
  labs(title = "Changes in the Valence of Popular Songs over Time",
       x = "Year",
       y = "Mean Valence Score")
```
Although to a lesser degree than danceability and energy, the mean valence of songs has also decreased throughout the decade. 

###Live
Since 2012, over 50% of the Western population has owned a smartphone. This change has driven large changes in how people communicate, interact and socialise. Although the COVID-19 pandemic certainly decreased the likelihood that music was recorded live, I wanted to see whether the average likelihood of a song being recorded live had been decreasing *prior* to lockdowns. 

```{r}
mean_live<- 
  spotify_data %>%
  group_by(year) %>%
  summarise_at(vars(live), list(live = mean))
mean_live
```
Now, any changes in the mean live score can be visualised here
```{r}
ggplot(mean_live, aes(x = year, y = live)) +
  geom_line() +
  labs(title = "Changes in The Mean Likelihood of A Top Song Being A Live Recording Over Time",
       x = "Year",
       y = "Mean Live Score")
```

### Summary 
As seen in these visualisations, the mean valence, likelihood of a song being recorded live, and energy of songs has been decreasing over time, indicating a shift in audience tastes throughout the decade. However, these findings sharply contrast with a general increase in the average song's danceability over time : while audiences of the 2020s may be more likely to listen to low valence, low energy songs that arent' recorded live, they are also more likely to listen to songs that have a high danceability factor. 
## LINEAR REGRESSION : ENERGY & VALENCE

 Both the mean valence and mean energy of popular songs appear to have decreased over time in a similar fashion. This could suggest that there is a relationship between trends in valence and trends in energy : if energy and valence are related, data-driven trend forecasters could predict changes in the characteristics of popular songs by only following one metric. 
 
 To test for this relationship, I have elected to perform a linear regression. This method only makes two assumptions : that of linearity, and that of no anomalies.
 
 First, I am testing for the presence of a linear relationship, with this specific question : 
" Is there a linear relationship between the'Valence' and 'Energy' in the Spotify Top 10s 2010-2019 dataset?"
  Based on the visualisations above, my hypothesis is that the relationship between the two variables should be greater than zero

### Descriptives
First, I am examining the means and standard deviations of the two variables.

```{r}
favstats(~val, data=spotify_data)
favstats(~nrgy, data=spotify_data)
```
Neither column appears to contain irrelevant data or missing values.

Inspecting the descriptives shows that the Valence variable has a mean of 52.4, and a standard deviation of 22.5. Most mean valence scores appear to fall above the scale median, but there is a large degree of variation around this average. The Energy variable, on the other hand, has a mean of 70.6, and a standard deviation of 16.0. It is difficult to interpret the meaning of this mean score, but it appears that the majority of the variables cluster above the mean. It is certain that there is greater variance across valence scores compared to energy scors. 

### Correlation between Valence and Energy
An initial step in any test of relationships is to inspect the extent to which our variables co-vary. 
```{r}
val_nrgy_cov <- spotify_data %>%
  select(val,nrgy)

cov(val_nrgy_cov, method="pearson")
```
The covariance of valence and energy is 147.12. This is a positive value and indicates a positive relationship between song valence and energy. However, this number does not indicate the size of the covariance, as the level of the covariance depends on the scale of measurement for these variables. 

As such, a standardised metric of covariance is required : Pearson's R - a standardised metric that
runs between -1 and +1. The closer Pearson's r is to +/-1, the larger the relationship.

```{r}
cor(val_nrgy_cov)
```

 Pearson's r is 0.41. According to Cohen (1988, 1992), the effect size is low if the value of r varies around 0.1, medium if r varies around 0.3, and large if r varies more than 0.5. An r of .41 is a medium correlation.
 
 The rcorr function can indicate the significance of this Pearson's R

```{r}
library(Hmisc)
rcorr(as.matrix(val_nrgy_cov))
```

We can see that Pearson's r is the same as we have calculated but the difference here is that underneath the correlation matrix we have a matrix for P. The p value associated with our correlation coeffcient is 0, therefore we can reject the null hypothesis. A zero relationship seems unlikely in the population. The positive correlation between valence and energy is, therefore, statistically significant.

I have visualised this relationship via a scatterplot

```{r}
spotify_data %>%
ggplot(aes(x = nrgy, y = val)) +
    geom_point() +
  theme_classic(base_size = 8)+
  labs(title = "Relationship Between Valence and Energy : Top Songs 2010-2019",
       x = "Energy",
       y = "Valence")
```

The scatterplot supports the information we called from the correlation matrix. There is a quite strong positive relationship apparent in this data. As Energy increases, so Valence increases. The degree of energy in a song appears to contribute to its valence.

I have also elected to draw the best-fitting regression line : 

```{r}
spotify_data %>%
ggplot(aes(x = nrgy, y = val)) + 
    geom_point() +
    stat_smooth(method = "lm",
        col = "red",
        se = FALSE,
        linewidth = 1) +
  theme_classic(base_size = 8)+
    labs(title = "Relationship Between Valence and Energy : Top Songs 2010-2019",
       x = "Energy",
       y = "Valence")
```


### Setting up the linear regression model of Valence

Given evidence for a linear relationship between valence and energy, I built a linear model of valence to examine the extent to which a song's energy predicted its valence. 

```{r}
valence.model <- lm(val ~ 1 + nrgy, data = spotify_data)
summary(valence.model)
```
The intercept, or b0 is 11.8, which represents the predicted valence when nrgy = 0. The nrgy estimate, or b1 is 0.57 : for every one unit increase in a song's energy, there is an estimated 0.57 unit increase in valence. Alongside this value there is standard error, and a t-ratio. 

The p-value associated the the t-ratio is below 0.05, and therefore, Energy appears to be a statistically significant predictor of a song's valence!

### Standardized estimates

I also calculated the standardised estimates, as this provides a measure of magnitude, or how large the relationship between energy and valence is. 

```{r}
spotify_data$zval <- scale(spotify_data$val)
spotify_data$znrgy <- scale(spotify_data$nrgy)
spotify_data
```

Once this was achieved I ran the linear model with the z-scores rather than the original scores.

```{r}
valence.modelZ <- lm(zval ~ 1 + znrgy, data = spotify_data)
summary(valence.modelZ)
```
The standardised estimate for the slope of energy and valence is 0.409. This indicates that for every one standardised deviation unit increase in energy, there is a 0.409 standardised deviation increase in valence. As all the p-values are below 0.05, this is, as expected, a significant effect. 

### Partitioning variance
With a regression line, it is possible for myself, or any spotify executive, to make predictions about a song's valence for any given energy score. Of course, there will be some error in this estimation, which is calculated as the difference between the predicted score, and the observed scores in the data. 
To partition the variance, I used the predict() function to calculate the predicted scores, and saved them in a new variable called 'predicted_val)

```{r}
spotify_data$predicted_val <- predict(valence.model)
spotify_data
```
The predicted scores returned by the regression model differ depending on each specific value of the continuous energy variable.

Residuals are calculated as the difference between the predicted valence score and the observed valence score. I used the resid() function to calculate the residuals and save these as a new variable called residuals in the dataframe

```{r}
spotify_data$residuals <- resid(valence.model)
spotify_data
```

To examine the amount of error in the linear model developed, I called the sum of squares :
```{r}
sum(spotify_data$residuals^2)
```

In this regression model, the sum of squares of 246304.3. 

To determine whether this sum of squares is meaningfully large, I partitioned this variance using supernova(), which allows me to examine what proportion of the variance in song valence is predicted by its energy

```{r}
supernova(valence.model)
```
The PRE or predicted reduction in error is 0.17, which means that Energy explains 17% of the variance in Valence. 
The F ratio, or the ratio of the mean square of the mdoel to the mean square for the error is 118.13. The larger the F, the larger the ratio of variance explaiend by the model. 
The p-value associated with the F is zero. 

Finally, I visualised all of this information in a plot that contains the correlation coefficient :

```{r}
spotify_data %>%
ggplot(aes(x = nrgy, y = val)) +
    geom_point() +
    stat_smooth(method = "lm",
        col = "red",
        se = FALSE,
        size = 1) +
  theme_classic(base_size = 8) +
  stat_cor() + # the retruns the correlation coefficient 
  stat_regline_equation(label.y = 7)+ # this returns the GLM equation
  labs(title = "Relationship Between Valence and Energy : Top Songs 2010-2019",
       x = "Energy",
       y = "Valence")
```

### Summary

A simple regression analysis was performed to test the relationship between energy and valence in the Spotify Top 10s 2010-2019 data. The regression model indicated that valence explained 17% of the variance in Valence (R = 0.41, F(1) = 118.13, p < .001). Inspection of the model estimates indicated that Energy positively predicted Valence (b =0.57, Î² = .41, t (586) = 10.82, p < .001). 

These findings indicate that a song's valence can be predicted by its level of energy. As both average energy and valence have been decreasing over time, a record label choosing to invest in an artist may only have to look at the general energy of their songs in order to evaluate their music's valence and vice versa. Furthermore, playlist design could be aligned towards only one axis : instead of separating songs by valence /and/ energy, they could be classified by energy alone, with valence taken as a subcomponent of energy. 

## BUILDING A CLASSIFIER

Building a classifier to identify the genre of a song could improve Spotify's classification. In looking through this data set, I have noticed that the genre of a song seems inextricably tied to the artist: it is a key assumption of this dataset that an artists songs are all within the same genre. 

To try and improve the classification of music, I have built and trained a classifier to predict a song's genre based on the characteristics of the music. Beyond improving genre's accuracy, this could assist in playlist creation, and in identifying increasing interest in niche genres. 

### Installing & Loading packages for building classifiers
I've installed and downloaded the caret package, and set the seed to a random number to make this machine learning experiment reproducible. I have also trimmed down the data to be only the variables relevant to the training set. 
```{r}
library(caret)
trSpotify <-
  spotify_data%>%
  select(genre,bpm,nrgy,dnce,dB,live,val,dur,acous,spch,pop)
glimpse(trSpotify)
```
The output shows that the dataset has one factor variable and 10 double class variables
### Data Partitioning
The model is built on the training data set, and its performance is evaluated on a test dataset : I amusing the holdout validation approach to evaluating model performance. 

The first line of code below sets the random seed for reproducibility of results. 

The second and third lines then load the caTools package that I use for data partitioning, while the fourth to sixth lines create the training and test sets from the trSpotify dataset. 

The training dataset contails 70% of the data, while the test dataset contails the remaining 30% : 
```{r}
#Set Random Seed
set.seed(15)

#Install and Download caTools
library(caTools)

#Splitting the data
spl = sample.split(trSpotify$genre, SplitRatio = 0.7)
train = subset(trSpotify,spl == TRUE)
test = subset(trSpotify,spl == FALSE)

print(dim(train));print(dim(test))
```
### Building, Predicting and Evaluating the Model 
To fit the logistic regression model, the first step is to instatiate the algoritm. I have done this using the glm() function. I have also printed the summary of the trained model : 
```{r}
genre_glm = glm(genre~ . , family ="binomial", data=train)
summary(genre_glm)
```
None of the singular variables appear to be significant predictors of a song's genre : this further indicates that genre may have little relationship to a song's musical qualities and is decided based on the artist. 

Let's evaluate the model further, starting by setting the baseline accuracy using the code below. Since the majority class of the target variable has a proportion of 325/588 = 0.55, the baseline accuracy is 55 percent.
```{r}
#Baseline Accuracy
prop.table(table(train$genre))
```
I can now evaluate the model performance on the training and test data, which should ideally be better than the baseline accuracy. I can start by generating predictions on the training data, using the first line of code below. 
The second line cerates the confusion matrix with a threshhold of 0.5, which sets 0.5 likelihood as an indicator of a true positive. 

The third line prints the accuracy of the model on the training data, using the confusion matrix. 
```{r}
# Predictions on the training set
predictTrain = predict(genre_glm, data = train, type = "response")

# Confusion matrix on training data
table(train$genre, predictTrain >= 0.5)
409/nrow(train) #accuracy of training set 

#Predictions on the test set
predictTest = predict(genre_glm, newdata = test, type = "response")

# Confusion matrix on test set
table(test$genre, predictTest >= 0.5)
178/nrow(test) #accuracy of testing set
```

The accuracy of the model on the training data is 100%, which is as expected, but when imposed on the test data, the accuracy comes out to 99%


### Conclusion From Classifier
 The baseline accuracy for the data was 55 percent, while the accuracy on the training and test data was 100 percent, and 99.5 percent, respectively. Overall, the logistic regression model is beating the baseline accuracy by a big margin on both the train and test datasets, and the results are very good. This indicates that a combination of the song's variables, that don't include the artist, are strong predictors of the song's success. 
 



